{"nbformat":4,"nbformat_minor":2,"metadata":{"orig_nbformat":4,"language_info":{"name":"python","version":"3.8.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"name":"python3","display_name":"Python 3.8.11 64-bit ('base': conda)"},"interpreter":{"hash":"dca0ade3e726a953b501b15e8e990130d2b7799f14cfd9f4271676035ebe5511"},"colab":{"name":"CNN.ipynb","provenance":[]},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"source":["from google.colab import drive\n","drive.mount('/content/drive/')"],"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive/\n"]}],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PwtJYM2i8Qy3","executionInfo":{"status":"ok","timestamp":1633261115724,"user_tz":-480,"elapsed":58553,"user":{"displayName":"Hugo Yang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhT1MWGXdLgyfwzVH6jVdurGpK8sZiCccuLj6qH=s64","userId":"13954216390922923355"}},"outputId":"b650e78c-b91c-4620-d002-316b825a25c9"}},{"cell_type":"code","execution_count":null,"source":["# 指定当前的工作文件夹\n","import os\n","# 此处为google drive中的文件路径,drive为之前指定的工作根目录，要加上\n","os.chdir(\"/content/drive/MyDrive/Colab Notebooks/\") "],"outputs":[],"metadata":{"id":"17K7I2lD81ES"}},{"cell_type":"code","execution_count":null,"source":["!gdown --id '19CzXudqN58R3D-1G8KeFWk8UDQwlb8is' --output food-11.zip # 下載資料集\n","!unzip food-11.zip # 解壓縮"],"outputs":[],"metadata":{"id":"4FfeBGrT7WYl"}},{"cell_type":"code","execution_count":null,"source":["import os\n","import numpy as np\n","import pandas as pd\n","import cv2\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import DataLoader, Dataset\n","import torchvision.transforms as transforms\n","import time"],"outputs":[],"metadata":{"id":"ZHUzYson7WYp"}},{"cell_type":"markdown","source":["## Read Image\n","利用OpenCV(cv2)读入照片并存放在numpy array中"],"metadata":{"id":"vh3108vT7WYq"}},{"cell_type":"code","execution_count":null,"source":["def readfile(path, label):\n","  # label是一个布尔值，代表需不需要回传y值\n","  image_dir = sorted(os.listdir(path))\n","  x = np.zeros((len(image_dir), 128, 128, 3), dtype=np.uint8)\n","  y = np.zeros((len(image_dir)), dtype=np.uint8)\n","  for i, file in enumerate(image_dir):\n","    img = cv2.imread(os.path.join(path, file))\n","    x[i, :, :] = cv2.resize(img, (128, 128))\n","    if label:\n","      y[i] = int(file.split(\"_\")[0])\n","  if label:\n","    return x, y\n","  else:\n","    return x"],"outputs":[],"metadata":{"id":"gfqRa9Vk7WYr"}},{"cell_type":"code","execution_count":null,"source":["# 分别将training set、validation set、testing set用readfile函数读入\n","workspace_dir = './food-11'\n","print('reading data')\n","train_x, train_y = readfile(os.path.join(workspace_dir, 'training'), True)\n","print('size of training data = {}'.format(len(train_x)))\n","val_x, val_y = readfile(os.path.join(workspace_dir, 'validation'), True)\n","print('size of validation data = {}'.format(len(val_x)))\n","test_x = readfile(os.path.join(workspace_dir, 'testing'), False)\n","print('size of testing data = {}'.format(len(test_x)))"],"outputs":[{"output_type":"stream","name":"stdout","text":["reading data\n","size of training data = 9866\n","size of validation data = 3430\n","size of testing data = 3347\n"]}],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Nu0AtNL37WYs","executionInfo":{"status":"ok","timestamp":1633262101444,"user_tz":-480,"elapsed":171174,"user":{"displayName":"Hugo Yang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhT1MWGXdLgyfwzVH6jVdurGpK8sZiCccuLj6qH=s64","userId":"13954216390922923355"}},"outputId":"7ad6c215-f534-47d6-b6ee-65fc96c69325"}},{"cell_type":"markdown","source":["# Dataset\n","利用pytorch的Dataset来“包装”data，是后续的training和testing更为方便"],"metadata":{"id":"pnEaJTQ37WYs"}},{"cell_type":"code","execution_count":null,"source":["# training 時做 data augmentation\n","train_transform = transforms.Compose([\n","    transforms.ToPILImage(),\n","    transforms.RandomHorizontalFlip(), # 隨機將圖片水平翻轉\n","    transforms.RandomRotation(15), # 隨機旋轉圖片\n","    transforms.ToTensor(), # 將圖片轉成 Tensor，並把數值 normalize 到 [0,1] (data normalization)\n","])\n","# testing 時不需做 data augmentation\n","test_transform = transforms.Compose([\n","    transforms.ToPILImage(),                                    \n","    transforms.ToTensor(),\n","])\n","\n","class ImgDataset(Dataset):\n","  def __init__(self, x, y=None, transform=None):\n","    self.x = x\n","    self.y = y\n","    if y is not None:\n","      self.y = torch.LongTensor(y)\n","    self.transform = transform\n","  \n","  def __len__(self):\n","    return len(self.x)\n","\n","  def __getitem__(self, index):\n","    X = self.x[index]\n","    if self.transform is not None:\n","      X = self.transform(X)\n","    if self.y is not None:\n","      Y = self.y[index]\n","      return X, Y\n","    else:\n","      return X"],"outputs":[],"metadata":{"id":"owegzsWz7WYt"}},{"cell_type":"code","execution_count":null,"source":["batch_size = 128\n","train_set = ImgDataset(train_x, train_y, train_transform)\n","val_set = ImgDataset(val_x, val_y, test_transform)\n","train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n","val_loader = DataLoader(val_set, batch_size=batch_size, shuffle=False)"],"outputs":[],"metadata":{"id":"m1RfSGdJ7WYu"}},{"cell_type":"markdown","source":["# Model"],"metadata":{"id":"mF6dGtCN7WYu"}},{"cell_type":"code","execution_count":25,"source":["class Classifier(nn.Module):\n","    def __init__(self):\n","        super(Classifier, self).__init__()\n","        # torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding)\n","        # torch.nn.MaxPool2d(kernel_size, stride, padding)\n","        # input 維度 [3, 128, 128]\n","        self.cnn = nn.Sequential(\n","            nn.Conv2d(3, 64, 3, 1, 1),  # [64, 128, 128]\n","            nn.BatchNorm2d(64),\n","            nn.ReLU(),\n","            nn.MaxPool2d(2, 2, 0),      # [64, 64, 64]\n","\n","            nn.Conv2d(64, 128, 3, 1, 1), # [128, 64, 64]\n","            nn.BatchNorm2d(128),\n","            nn.ReLU(),\n","            nn.MaxPool2d(2, 2, 0),      # [128, 32, 32]\n","\n","            nn.Conv2d(128, 256, 3, 1, 1), # [256, 32, 32]\n","            nn.BatchNorm2d(256),\n","            nn.ReLU(),\n","            nn.MaxPool2d(2, 2, 0),      # [256, 16, 16]\n","\n","            nn.Conv2d(256, 512, 3, 1, 1), # [512, 16, 16]\n","            nn.BatchNorm2d(512),\n","            nn.ReLU(),\n","            nn.MaxPool2d(2, 2, 0),       # [512, 8, 8]\n","            \n","            nn.Conv2d(512, 512, 3, 1, 1), # [512, 8, 8]\n","            nn.BatchNorm2d(512),\n","            nn.ReLU(),\n","            nn.MaxPool2d(2, 2, 0),       # [512, 4, 4]\n","        )\n","        self.fc = nn.Sequential(\n","            nn.Linear(512*4*4, 1024),\n","            nn.ReLU(),\n","            nn.Linear(1024, 512),\n","            nn.ReLU(),\n","            nn.Linear(512, 11)\n","        )\n","\n","    def forward(self, x):\n","        out = self.cnn(x)\n","        out = out.view(out.size()[0], -1)\n","        return self.fc(out)"],"outputs":[],"metadata":{"id":"NUdj-eJP7WYv","executionInfo":{"status":"ok","timestamp":1633265642000,"user_tz":-480,"elapsed":840,"user":{"displayName":"Hugo Yang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhT1MWGXdLgyfwzVH6jVdurGpK8sZiCccuLj6qH=s64","userId":"13954216390922923355"}}}},{"cell_type":"markdown","source":["# Training\n","使用training set训练，并使用validation set寻找好的参数"],"metadata":{"id":"ELtloZnH7WYw"}},{"cell_type":"code","execution_count":null,"source":["model = Classifier()\n","loss = nn.CrossEntropyLoss() # 因為是 classification task，所以 loss 使用 CrossEntropyLoss\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.001) # optimizer 使用 Adam\n","num_epoch = 30\n","\n","for epoch in range(num_epoch):\n","    epoch_start_time = time.time()\n","    train_acc = 0.0\n","    train_loss = 0.0\n","    val_acc = 0.0\n","    val_loss = 0.0\n","\n","    model.train() # 確保 model 是在 train model (開啟 Dropout 等...)\n","    for i, data in enumerate(train_loader):\n","        optimizer.zero_grad() # 用 optimizer 將 model 參數的 gradient 歸零\n","        train_pred = model(data[0]) # 利用 model 得到預測的機率分佈 這邊實際上就是去呼叫 model 的 forward 函數\n","        batch_loss = loss(train_pred, data[1]) # 計算 loss （注意 prediction 跟 label 必須同時在 CPU 或是 GPU 上）\n","        batch_loss.backward() # 利用 back propagation 算出每個參數的 gradient\n","        optimizer.step() # 以 optimizer 用 gradient 更新參數值\n","\n","        train_acc += np.sum(np.argmax(train_pred.data.numpy(), axis=1) == data[1].numpy())\n","        train_loss += batch_loss.item()\n","    \n","    model.eval()\n","    with torch.no_grad():\n","        for i, data in enumerate(val_loader):\n","            val_pred = model(data[0])\n","            batch_loss = loss(val_pred, data[1])\n","\n","            val_acc += np.sum(np.argmax(val_pred.data.numpy(), axis=1) == data[1].numpy())\n","            val_loss += batch_loss.item()\n","\n","        #將結果 print 出來\n","        print('[%03d/%03d] %2.2f sec(s) Train Acc: %3.6f Loss: %3.6f | Val Acc: %3.6f loss: %3.6f' % \\\n","            (epoch + 1, num_epoch, time.time()-epoch_start_time, \\\n","             train_acc/train_set.__len__(), train_loss/train_set.__len__(), val_acc/val_set.__len__(), val_loss/val_set.__len__()))"],"outputs":[],"metadata":{"id":"IZNdvNGg7WYw"}},{"cell_type":"markdown","source":["得到好的参数后，使用training set和validation set共同训练，data量变多，模型效果较好"],"metadata":{"id":"xRnaEdV97WYx"}},{"cell_type":"code","execution_count":null,"source":["train_val_x = np.concatenate((train_x, val_x), axis=0)\n","train_val_y = np.concatenate((train_y, val_y), axis=0)\n","train_val_set = ImgDataset(train_val_x, train_val_y, train_transform)\n","train_val_loader = DataLoader(train_val_set, batch_size=batch_size, shuffle=True)"],"outputs":[],"metadata":{"id":"2RC4lL6n7WYx","executionInfo":{"status":"aborted","timestamp":1633264877944,"user_tz":-480,"elapsed":7,"user":{"displayName":"Hugo Yang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhT1MWGXdLgyfwzVH6jVdurGpK8sZiCccuLj6qH=s64","userId":"13954216390922923355"}}}},{"cell_type":"code","execution_count":null,"source":["model_best = Classifier()\n","loss = nn.CrossEntropyLoss() # 因為是 classification task，所以 loss 使用 CrossEntropyLoss\n","optimizer = torch.optim.Adam(model_best.parameters(), lr=0.001) # optimizer 使用 Adam\n","num_epoch = 30\n","\n","for epoch in range(num_epoch):\n","    epoch_start_time = time.time()\n","    train_acc = 0.0\n","    train_loss = 0.0\n","\n","    model_best.train()\n","    for i, data in enumerate(train_val_loader):\n","        optimizer.zero_grad()\n","        train_pred = model_best(data[0])\n","        batch_loss = loss(train_pred, data[1])\n","        batch_loss.backward()\n","        optimizer.step()\n","\n","        train_acc += np.sum(np.argmax(train_pred.cpu().data.numpy(), axis=1) == data[1].numpy())\n","        train_loss += batch_loss.item()\n","\n","        #將結果 print 出來\n","    print('[%03d/%03d] %2.2f sec(s) Train Acc: %3.6f Loss: %3.6f' % \\\n","      (epoch + 1, num_epoch, time.time()-epoch_start_time, \\\n","      train_acc/train_val_set.__len__(), train_loss/train_val_set.__len__()))"],"outputs":[],"metadata":{"id":"7Y6KqqIx7WYx","executionInfo":{"status":"aborted","timestamp":1633264877945,"user_tz":-480,"elapsed":8,"user":{"displayName":"Hugo Yang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhT1MWGXdLgyfwzVH6jVdurGpK8sZiCccuLj6qH=s64","userId":"13954216390922923355"}}}},{"cell_type":"markdown","source":["# Testing"],"metadata":{"id":"A5_qOjWJ7WYx"}},{"cell_type":"code","execution_count":null,"source":["test_set = ImgDataset(test_x, transform=test_transform)\n","test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False)"],"outputs":[],"metadata":{"id":"q2V8Vi2b7WYy","executionInfo":{"status":"aborted","timestamp":1633264877946,"user_tz":-480,"elapsed":8,"user":{"displayName":"Hugo Yang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhT1MWGXdLgyfwzVH6jVdurGpK8sZiCccuLj6qH=s64","userId":"13954216390922923355"}}}},{"cell_type":"code","execution_count":null,"source":["model_best.eval()\n","prediction = []\n","with torch.no_grad():\n","  for i, data in enumerate(test_loader):\n","    test_pred = model_best(data)\n","    test_label = np.argmax(test_pred.cpu().data.numpy(), axis=1)\n","    for y in test_label:\n","      prediction.append(y)"],"outputs":[],"metadata":{"id":"bsXBoIEs7WYy","executionInfo":{"status":"aborted","timestamp":1633264877947,"user_tz":-480,"elapsed":9,"user":{"displayName":"Hugo Yang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhT1MWGXdLgyfwzVH6jVdurGpK8sZiCccuLj6qH=s64","userId":"13954216390922923355"}}}},{"cell_type":"code","execution_count":null,"source":["# 结果写入csv\n","with open('prediction.csv', 'w') as f:\n","  f.write('Id, category\\n')\n","  for i, y in enumerate(prediction):\n","    f.write('{},{}\\n'.format(i, y)) "],"outputs":[],"metadata":{"id":"AQfWjG4_7WYy","executionInfo":{"status":"aborted","timestamp":1633264877948,"user_tz":-480,"elapsed":10,"user":{"displayName":"Hugo Yang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhT1MWGXdLgyfwzVH6jVdurGpK8sZiCccuLj6qH=s64","userId":"13954216390922923355"}}}}]}