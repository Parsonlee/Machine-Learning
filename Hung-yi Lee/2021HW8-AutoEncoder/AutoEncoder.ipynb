{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JRpYpKBgCdZ_"
      },
      "source": [
        "# AutoEncoder\n",
        "\n",
        "Task: Anomaly detection  \n",
        "\n",
        "kaggle: https://www.kaggle.com/c/ml2021spring-hw8"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZWa7yeaaCdaC"
      },
      "source": [
        "## Import"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "metadata": {
        "id": "cyabex8ECdaC"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, TensorDataset, RandomSampler, SequentialSampler\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import Adam, AdamW\n",
        "from torch.autograd import Variable\n",
        "\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.models as models\n",
        "\n",
        "from sklearn.cluster import MiniBatchKMeans\n",
        "from scipy.cluster.vq import vq, kmeans"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 128,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aCCVMeX4CdaE",
        "outputId": "b945bb7f-df5d-4951-d5da-eb3737d23607"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(140001, 64, 64, 3)\n",
            "(19999, 64, 64, 3)\n"
          ]
        }
      ],
      "source": [
        "train = np.load('data-bin/trainingset.npy', allow_pickle=True)\n",
        "test = np.load('data-bin/testingset.npy', allow_pickle=True)\n",
        "\n",
        "print(train.shape)\n",
        "print(test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tbmIcrYZCdaE"
      },
      "source": [
        "## AutoEncoder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kxl4X-JnCdaE"
      },
      "source": [
        "### Models & loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TIQrw1AKCdaF"
      },
      "source": [
        "#### CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "metadata": {
        "id": "AAixm5dhCdaF"
      },
      "outputs": [],
      "source": [
        "class conv_autoencoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(conv_autoencoder, self).__init__()\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Conv2d(3, 12, 4, stride=2, padding=1),         \n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(12, 24, 4, stride=2, padding=1),        \n",
        "            nn.ReLU(),\n",
        "\t\t\t      nn.Conv2d(24, 48, 4, stride=2, padding=1),         \n",
        "            nn.ReLU(),\n",
        "            # nn.Conv2d(48, 96, 4, stride=2, padding=1),   # medium: remove this layer\n",
        "            # nn.ReLU(),\n",
        "        )\n",
        "        self.decoder = nn.Sequential(\n",
        "            # nn.ConvTranspose2d(96, 48, 4, stride=2, padding=1), # medium: remove this layer\n",
        "            # nn.ReLU(),\n",
        "            nn.ConvTranspose2d(48, 24, 4, stride=2, padding=1), \n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(24, 12, 4, stride=2, padding=1), \n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(12, 3, 4, stride=2, padding=1),\n",
        "            nn.Tanh(),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.encoder(x)\n",
        "        x = self.decoder(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OCnUrFpCCdaG"
      },
      "source": [
        "#### VAE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "khA8fHGaCdaH"
      },
      "outputs": [],
      "source": [
        "class VAE(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(VAE, self).__init__()\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Conv2d(3, 12, 4, stride=2, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(12, 24, 4, stride=2, padding=1),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "        self.enc_out1 = nn.Sequential(\n",
        "            nn.Conv2d(24, 48, 4, stride=2, padding=1),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "        self.enc_out2 = nn.Sequential(\n",
        "            nn.Conv2d(24, 48, 4, stride=2, padding=1),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.ConvTranspose2d(48, 24, 4, stride=2, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(24, 12, 4, stride=2, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(12, 3, 4, stride=2, padding=1),\n",
        "            nn.Tanh(),\n",
        "        )\n",
        "\n",
        "    def encode(self, x):\n",
        "        h1 = self.encoder(x)\n",
        "        return self.enc_out1(h1), self.enc_out2(h1)\n",
        "\n",
        "    # Add Gaussian noise to the latent vector\n",
        "    def reparametrize(self, mu, logvar):\n",
        "        std = logvar.mul(0.5).exp_()\n",
        "        if torch.cuda.is_available():\n",
        "            eps = torch.cuda.FloatTensor(std.size()).normal_()\n",
        "        else:\n",
        "            eps = torch.FloatTensor(std.size()).normal_()\n",
        "        eps = Variable(eps)\n",
        "        return eps.mul(std).add_(mu)\n",
        "\n",
        "    def decode(self, z):\n",
        "        return self.decoder(z)\n",
        "\n",
        "    def forward(self, x):\n",
        "        mu, logvar = self.encode(x)\n",
        "        z = self.reparametrize(mu, logvar)\n",
        "        return self.decode(z), mu, logvar\n",
        "\n",
        "def loss_vae(recon_x, x, mu, logvar, criterion):\n",
        "    \"\"\"\n",
        "    recon_x: generating images\n",
        "    x: origin images\n",
        "    mu: latent mean\n",
        "    logvar: latent log variance\n",
        "    \"\"\"\n",
        "    mse = criterion(recon_x, x)  # mse loss\n",
        "    KLD_element = mu.pow(2).add_(logvar.exp()).mul_(-1).add_(1).add_(logvar)\n",
        "    KLD = torch.sum(KLD_element).mul_(-0.5)\n",
        "    # KL divergence\n",
        "    return mse + KLD"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-CThUUkRCdaI"
      },
      "source": [
        "#### Resnet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "metadata": {
        "id": "v9yb83NFCdaI"
      },
      "outputs": [],
      "source": [
        "class Resnet(nn.Module):\n",
        "    def __init__(self, fc_hidden1=1024, fc_hidden2=768, drop_p=0.3, CNN_embed_dim=256):\n",
        "        super(Resnet, self).__init__()\n",
        "\n",
        "        self.fc_hidden1, self.fc_hidden2, self.CNN_embed_dim = fc_hidden1, fc_hidden2, CNN_embed_dim\n",
        "\n",
        "        # CNN architechtures\n",
        "        self.ch1, self.ch2, self.ch3, self.ch4 = 16, 32, 64, 128\n",
        "        self.k1, self.k2, self.k3, self.k4 = (5, 5), (3, 3), (3, 3), (3, 3)      # 2d kernal size\n",
        "        self.s1, self.s2, self.s3, self.s4 = (2, 2), (2, 2), (2, 2), (2, 2)      # 2d strides\n",
        "        self.pd1, self.pd2, self.pd3, self.pd4 = (0, 0), (0, 0), (0, 0), (0, 0)  # 2d padding\n",
        "\n",
        "        # encoding components\n",
        "        resnet = models.resnet18(pretrained=False)\n",
        "        modules = list(resnet.children())[:-1]      # delete the last fc layer.\n",
        "        self.resnet = nn.Sequential(*modules)\n",
        "        self.fc1 = nn.Linear(resnet.fc.in_features, self.fc_hidden1)\n",
        "        self.bn1 = nn.BatchNorm1d(self.fc_hidden1, momentum=0.01)\n",
        "        self.fc2 = nn.Linear(self.fc_hidden1, self.fc_hidden2)\n",
        "        self.bn2 = nn.BatchNorm1d(self.fc_hidden2, momentum=0.01)\n",
        "\n",
        "        self.fc3_mu = nn.Linear(self.fc_hidden2, self.CNN_embed_dim)      # output = CNN embedding latent variables\n",
        "\n",
        "        # Sampling vector\n",
        "        self.fc4 = nn.Linear(self.CNN_embed_dim, self.fc_hidden2)\n",
        "        self.fc_bn4 = nn.BatchNorm1d(self.fc_hidden2)\n",
        "        self.fc5 = nn.Linear(self.fc_hidden2, 64 * 4 * 4)\n",
        "        self.fc_bn5 = nn.BatchNorm1d(64 * 4 * 4)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "        # Decoder\n",
        "        self.convTrans6 = nn.Sequential(\n",
        "            nn.ConvTranspose2d(in_channels=64, out_channels=32, kernel_size=self.k4, stride=self.s4,\n",
        "                               padding=self.pd4),\n",
        "            nn.BatchNorm2d(32, momentum=0.01),\n",
        "            nn.ReLU(inplace=True),\n",
        "        )\n",
        "        self.convTrans7 = nn.Sequential(\n",
        "            nn.ConvTranspose2d(in_channels=32, out_channels=8, kernel_size=self.k3, stride=self.s3,\n",
        "                               padding=self.pd3),\n",
        "            nn.BatchNorm2d(8, momentum=0.01),\n",
        "            nn.ReLU(inplace=True),\n",
        "        )\n",
        "\n",
        "        self.convTrans8 = nn.Sequential(\n",
        "            nn.ConvTranspose2d(in_channels=8, out_channels=3, kernel_size=self.k2, stride=self.s2,\n",
        "                               padding=self.pd2),\n",
        "            nn.BatchNorm2d(3, momentum=0.01),\n",
        "            nn.Sigmoid()    # y = (y1, y2, y3) \\in [0 ,1]^3\n",
        "        )\n",
        "\n",
        "\n",
        "    def encode(self, x):\n",
        "        x = self.resnet(x)  # ResNet\n",
        "        x = x.view(x.size(0), -1)  # flatten output of conv\n",
        "\n",
        "        # FC layers\n",
        "        if x.shape[0] > 1:\n",
        "            x = self.bn1(self.fc1(x))\n",
        "        else:\n",
        "            x = self.fc1(x)\n",
        "        x = self.relu(x)\n",
        "        if x.shape[0] > 1:\n",
        "            x = self.bn2(self.fc2(x))\n",
        "        else:\n",
        "            x = self.fc2(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc3_mu(x)\n",
        "        return x\n",
        "\n",
        "    def decode(self, z):\n",
        "        if z.shape[0] > 1:\n",
        "            x = self.relu(self.fc_bn4(self.fc4(z)))\n",
        "            x = self.relu(self.fc_bn5(self.fc5(x))).view(-1, 64, 4, 4)\n",
        "        else:\n",
        "            x = self.relu(self.fc4(z))\n",
        "            x = self.relu(self.fc5(x)).view(-1, 64, 4, 4)\n",
        "        x = self.convTrans6(x)\n",
        "        x = self.convTrans7(x)\n",
        "        x = self.convTrans8(x)\n",
        "        x = F.interpolate(x, size=(64, 64), mode='bilinear', align_corners=True)\n",
        "        return x\n",
        "\n",
        "    def forward(self, x):\n",
        "        z = self.encode(x)\n",
        "        x_reconst = self.decode(z)\n",
        "\n",
        "        return x_reconst\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SQrolHauCdaJ"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "metadata": {
        "id": "SMOMeGSpCdaJ"
      },
      "outputs": [],
      "source": [
        "class CustomDataset(TensorDataset):\n",
        "    \"\"\"TensorDataset with support of transforms.\"\"\"\n",
        "    def __init__(self, tensors):\n",
        "        self.tensors = tensors\n",
        "        if tensors.shape[-1] == 3:\n",
        "            # (batch_size, 64, 64, 3) -> (batch_size, 3, 64, 64)\n",
        "            self.tensors = tensors.permute(0, 3, 1, 2)\n",
        "\n",
        "        self.transforms = transforms.Compose([\n",
        "            transforms.Lambda(lambda x: x.to(torch.float32)),\n",
        "            # Can't use:  transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
        "            # Will make LOSS explode(inf)\n",
        "            transforms.Lambda(lambda x: 2. * x/255. - 1.),\n",
        "        ])\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        x = self.tensors[index]\n",
        "        if self.transforms:\n",
        "            x = self.transforms(x)\n",
        "        return x\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.tensors)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZzKRvHDfCdaJ"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VECFPI8pCdaK"
      },
      "source": [
        "### Initalize\n",
        "- hyperparameters\n",
        "- dataloaders\n",
        "- model\n",
        "- loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 145,
      "metadata": {
        "id": "qXSnI8n9CdaK"
      },
      "outputs": [],
      "source": [
        "# hyperparameters\n",
        "epochs = 50\n",
        "batch_size = 512\n",
        "lr = 1e-3\n",
        "\n",
        "# dataloader\n",
        "x = torch.from_numpy(train)\n",
        "train_set = CustomDataset(x)\n",
        "\n",
        "train_sampler = RandomSampler(train_set)\n",
        "train_loader = DataLoader(train_set, batch_size=batch_size, sampler=train_sampler)\n",
        "\n",
        "# model\n",
        "model_type = 'resnet'\n",
        "model_classes = {'resnet': Resnet(), 'vae': VAE(), 'cnn': conv_autoencoder()}\n",
        "model = model_classes[model_type].cuda()\n",
        "\n",
        "# loss and optimizer\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = Adam(model.parameters(), lr=lr)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### debug"
      ],
      "metadata": {
        "id": "_qEOqaX4RFeF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# for data in train_loader:\n",
        "#   img = data.float().cuda()\n",
        "#   # forward\n",
        "#   output = model(img)\n",
        "#   print(\"recon_x: \", output[0].shape)\n",
        "#   # print(\"mu: \",output[1].shape)\n",
        "#   # print(\"logvar: \",output[2].shape)\n",
        "#   print(\"img: \", img.shape)\n",
        "#   print(criterion(output[0], img))\n",
        "#   mse = criterion(output[0], img)  # mse loss\n",
        "#   print(\"mse: \",mse)\n",
        "\n",
        "#   KLD_element = output[1].pow(2).add_(output[2].exp()).mul_(-1).add_(1).add_(output[2])\n",
        "#   print(\"KLD_element: \", KLD_element.shape)\n",
        "\n",
        "#   KLD = torch.sum(KLD_element).mul_(-0.5)\n",
        "#   print(\"KLD: \", KLD.shape)\n",
        "\n",
        "#   loss = mse + KLD\n",
        "#   print(\"loss: \", loss)\n",
        "#   break\n",
        "\n",
        "# for data in train_loader:\n",
        "#   img = data.float().cuda()\n",
        "#   # forward\n",
        "#   output = model(img)\n",
        "#   if model_type in ['vae']:\n",
        "#       loss = loss_vae(output[0], img, output[1], output[2], criterion)\n",
        "#       print(\"0\")\n",
        "#   else:\n",
        "#       loss = criterion(output, img)\n",
        "#       print(\"1\")\n",
        "#   print(loss)\n",
        "#   break"
      ],
      "metadata": {
        "id": "2KZ2l9HhKxgL"
      },
      "execution_count": 146,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_KOLcmRjCdaK"
      },
      "source": [
        "### Training loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 147,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 864
        },
        "id": "vyH33PCNCdaK",
        "outputId": "858229f9-fa5f-412c-bdce-a75c5c1d3682"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  2%|▏         | 1/50 [02:36<2:07:40, 156.33s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0 \tLoss: 0.5406\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  4%|▍         | 2/50 [05:12<2:05:03, 156.32s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1 \tLoss: 0.4401\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  6%|▌         | 3/50 [07:48<2:02:25, 156.28s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 2 \tLoss: 0.3877\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  8%|▊         | 4/50 [10:25<1:59:47, 156.25s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 3 \tLoss: 0.3538\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|█         | 5/50 [13:01<1:57:09, 156.21s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 4 \tLoss: 0.3302\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 12%|█▏        | 6/50 [15:37<1:54:33, 156.21s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 5 \tLoss: 0.3132\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 14%|█▍        | 7/50 [18:13<1:51:57, 156.22s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 6 \tLoss: 0.3007\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 16%|█▌        | 8/50 [20:49<1:49:20, 156.20s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 7 \tLoss: 0.2919\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 18%|█▊        | 9/50 [23:25<1:46:43, 156.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 8 \tLoss: 0.2848\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 10/50 [26:02<1:44:06, 156.17s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 9 \tLoss: 0.2786\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 22%|██▏       | 11/50 [28:38<1:41:31, 156.19s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 10 \tLoss: 0.2739\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 24%|██▍       | 12/50 [31:14<1:38:55, 156.19s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 11 \tLoss: 0.2700\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 26%|██▌       | 13/50 [33:50<1:36:18, 156.17s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 12 \tLoss: 0.2671\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 28%|██▊       | 14/50 [36:26<1:33:41, 156.15s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 13 \tLoss: 0.2647\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|███       | 15/50 [39:02<1:31:05, 156.15s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 14 \tLoss: 0.2621\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 32%|███▏      | 16/50 [41:38<1:28:27, 156.11s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 15 \tLoss: 0.2601\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 34%|███▍      | 17/50 [44:15<1:25:51, 156.11s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 16 \tLoss: 0.2586\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 36%|███▌      | 18/50 [46:50<1:23:12, 156.01s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 17 \tLoss: 0.2570\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 38%|███▊      | 19/50 [49:25<1:20:20, 155.49s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 18 \tLoss: 0.2559\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 20/50 [51:59<1:17:32, 155.09s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 19 \tLoss: 0.2549\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 42%|████▏     | 21/50 [54:34<1:14:58, 155.14s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 20 \tLoss: 0.2540\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 44%|████▍     | 22/50 [57:09<1:12:20, 155.03s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 21 \tLoss: 0.2531\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 46%|████▌     | 23/50 [59:43<1:09:39, 154.79s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 22 \tLoss: 0.2529\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 48%|████▊     | 24/50 [1:02:17<1:06:59, 154.60s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 23 \tLoss: 0.2521\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 25/50 [1:04:51<1:04:22, 154.50s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 24 \tLoss: 0.2512\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 52%|█████▏    | 26/50 [1:07:26<1:01:46, 154.43s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 25 \tLoss: 0.2507\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 54%|█████▍    | 27/50 [1:10:00<59:11, 154.43s/it]  "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 26 \tLoss: 0.2503\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 56%|█████▌    | 28/50 [1:12:34<56:36, 154.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 27 \tLoss: 0.2499\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 58%|█████▊    | 29/50 [1:15:09<54:01, 154.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 28 \tLoss: 0.2494\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 30/50 [1:17:43<51:27, 154.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 29 \tLoss: 0.2492\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 62%|██████▏   | 31/50 [1:20:18<48:58, 154.64s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 30 \tLoss: 0.2490\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 64%|██████▍   | 32/50 [1:22:54<46:30, 155.01s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 31 \tLoss: 0.2485\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 66%|██████▌   | 33/50 [1:25:30<44:00, 155.30s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 32 \tLoss: 0.2484\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 68%|██████▊   | 34/50 [1:28:06<41:28, 155.52s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 33 \tLoss: 0.2482\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|███████   | 35/50 [1:30:42<38:54, 155.64s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 34 \tLoss: 0.2478\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|███████   | 35/50 [1:32:34<39:40, 158.70s/it]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-147-f03441c7f0a3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0;31m# forward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "best_loss = np.inf\n",
        "model.train()\n",
        "\n",
        "for epoch in tqdm(range(epochs)):\n",
        "    total_loss = []\n",
        "\n",
        "    for data in train_loader:\n",
        "        img = data.float().cuda()\n",
        "        # forward\n",
        "        output = model(img)\n",
        "        if model_type in ['vae']:\n",
        "            loss = loss_vae(output[0], img, output[1], output[2], criterion)\n",
        "        else:\n",
        "            loss = criterion(output, img)\n",
        "        total_loss.append(loss.item())\n",
        "        # backward\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    \n",
        "    # save best model\n",
        "    mean_loss = np.mean(total_loss)\n",
        "    if mean_loss < best_loss:\n",
        "        torch.save(model, './best_model.pt')\n",
        "\n",
        "    print('Epoch: {} \\tLoss: {:.4f}'.format(epoch, mean_loss))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wNtkKV59CdaK"
      },
      "source": [
        "## Inference\n",
        "Model is loaded and generates its anomaly score predictions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6xPuuFbXCdaL"
      },
      "source": [
        "### Initalize\n",
        "- dataloader\n",
        "- model\n",
        "- predition file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 148,
      "metadata": {
        "id": "5Qsq859sCdaL"
      },
      "outputs": [],
      "source": [
        "eval_batch_size = 200\n",
        "\n",
        "# dataloader\n",
        "data = torch.tensor(test, dtype=torch.float32)\n",
        "test_set = CustomDataset(data)\n",
        "test_sampler = SequentialSampler(test_set)\n",
        "test_loader = DataLoader(test_set, batch_size=eval_batch_size, sampler=test_sampler, num_workers=1)\n",
        "eval_loss = nn.MSELoss(reduction='none')\n",
        "\n",
        "# load trained model\n",
        "model = torch.load('best_model.pt'.format(model_type))\n",
        "model.eval()\n",
        "\n",
        "# predict\n",
        "out_file = 'prediction.csv'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 149,
      "metadata": {
        "id": "P1G_mDhECdaL"
      },
      "outputs": [],
      "source": [
        "anomality = []\n",
        "with torch.no_grad():\n",
        "    for i, data in enumerate(test_loader):\n",
        "        img = data.float().cuda()\n",
        "        output = model(img)\n",
        "        \n",
        "        if model_type in ['cnn', 'resnet']:\n",
        "            output = output\n",
        "        elif model_type in ['vae']:\n",
        "            output = output[0]\n",
        "\n",
        "        loss = eval_loss(output, img).sum([1, 2, 3])\n",
        "        anomality.append(loss)\n",
        "\n",
        "anomality = torch.cat(anomality, dim=0)\n",
        "anomality = torch.sqrt(anomality).reshape(len(test), 1).cpu().numpy()\n",
        "\n",
        "df = pd.DataFrame(anomality, columns=['Predicted'])\n",
        "df.to_csv(out_file, index_label='Id')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#下载kaggle数据集#\n",
        "!pip install -U -q kaggle \n",
        "!mkdir -p ~/.kaggle\n",
        "!echo '{\"username\":\"hugoya\",\"key\":\"850b9322bfce66c8c2048a466b77cf33\"}' > ~/.kaggle/kaggle.json\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "#提交结果\n",
        "!kaggle competitions submit ml2021spring-hw8 -f ./prediction.csv -m \"resnet,batch512,1e-3\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bMn5OlwaiOGg",
        "outputId": "2ce54325-707b-4803-a24d-ceac70bb37b0"
      },
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100% 292k/292k [00:00<00:00, 318kB/s]\n",
            "Successfully submitted to ML2021spring - hw8"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "ZWa7yeaaCdaC",
        "TIQrw1AKCdaF",
        "OCnUrFpCCdaG",
        "-CThUUkRCdaI",
        "_qEOqaX4RFeF"
      ],
      "name": "AutoEncoder.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "0e963d61ae5592af78c1a29f643d857bd502442649449ec5cf61b348680e7239"
    },
    "kernelspec": {
      "display_name": "Python 3.9.10 ('dl')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}