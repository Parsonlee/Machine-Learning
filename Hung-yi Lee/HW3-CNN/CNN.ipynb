{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 下载数据集&导入包"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4FfeBGrT7WYl"
      },
      "outputs": [],
      "source": [
        "!gdown --id '19CzXudqN58R3D-1G8KeFWk8UDQwlb8is' --output food-11.zip # 下載資料集\n",
        "!unzip food-11.zip # 解壓縮"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ZHUzYson7WYp"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cv2\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torchvision.transforms as transforms\n",
        "import time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vh3108vT7WYq"
      },
      "source": [
        "## Read Image\n",
        "利用OpenCV(cv2)读入照片并存放在numpy array中"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "gfqRa9Vk7WYr"
      },
      "outputs": [],
      "source": [
        "def readfile(path, label):\n",
        "  # label是一个布尔值，代表需不需要回传y值\n",
        "  image_dir = sorted(os.listdir(path))\n",
        "  x = np.zeros((len(image_dir), 128, 128, 3), dtype=np.uint8)\n",
        "  y = np.zeros((len(image_dir)), dtype=np.uint8)\n",
        "  for i, file in enumerate(image_dir):\n",
        "    img = cv2.imread(os.path.join(path, file))\n",
        "    x[i, :, :] = cv2.resize(img, (128, 128))\n",
        "    if label:\n",
        "      y[i] = int(file.split(\"_\")[0])\n",
        "  if label:\n",
        "    return x, y\n",
        "  else:\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nu0AtNL37WYs",
        "outputId": "54f60a42-6d4e-414f-afa3-1586c5f4479f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "reading data\n",
            "size of training data = 9866\n",
            "size of validation data = 3430\n",
            "size of testing data = 3347\n"
          ]
        }
      ],
      "source": [
        "# 分别将training set、validation set、testing set用readfile函数读入\n",
        "workspace_dir = './food-11'\n",
        "print('reading data')\n",
        "train_x, train_y = readfile(os.path.join(workspace_dir, 'training'), True)\n",
        "print('size of training data = {}'.format(len(train_x)))\n",
        "val_x, val_y = readfile(os.path.join(workspace_dir, 'validation'), True)\n",
        "print('size of validation data = {}'.format(len(val_x)))\n",
        "test_x = readfile(os.path.join(workspace_dir, 'testing'), False)\n",
        "print('size of testing data = {}'.format(len(test_x)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pnEaJTQ37WYs"
      },
      "source": [
        "# Dataset\n",
        "利用pytorch的Dataset来“包装”data，是后续的training和testing更为方便"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "owegzsWz7WYt"
      },
      "outputs": [],
      "source": [
        "# training 時做 data augmentation\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.ToPILImage(),\n",
        "    transforms.RandomHorizontalFlip(), # 隨機將圖片水平翻轉\n",
        "    transforms.RandomRotation(15), # 隨機旋轉圖片\n",
        "    transforms.ToTensor(), # 將圖片轉成 Tensor，並把數值 normalize 到 [0,1] (data normalization)\n",
        "])\n",
        "# testing 時不需做 data augmentation\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.ToPILImage(),                                    \n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "class ImgDataset(Dataset):\n",
        "  def __init__(self, x, y=None, transform=None):\n",
        "    self.x = x\n",
        "    self.y = y\n",
        "    if y is not None:\n",
        "      self.y = torch.LongTensor(y)\n",
        "    self.transform = transform\n",
        "  \n",
        "  def __len__(self):\n",
        "    return len(self.x)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    X = self.x[index]\n",
        "    if self.transform is not None:\n",
        "      X = self.transform(X)\n",
        "    if self.y is not None:\n",
        "      Y = self.y[index]\n",
        "      return X, Y\n",
        "    else:\n",
        "      return X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "m1RfSGdJ7WYu"
      },
      "outputs": [],
      "source": [
        "batch_size = 128\n",
        "train_set = ImgDataset(train_x, train_y, train_transform)\n",
        "val_set = ImgDataset(val_x, val_y, test_transform)\n",
        "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_set, batch_size=batch_size, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mF6dGtCN7WYu"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "NUdj-eJP7WYv"
      },
      "outputs": [],
      "source": [
        "class Classifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Classifier, self).__init__()\n",
        "        # torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding)\n",
        "        # torch.nn.MaxPool2d(kernel_size, stride, padding)\n",
        "        # input 維度 [3, 128, 128]\n",
        "        self.cnn = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, 3, 1, 1),  # [64, 128, 128]\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2, 0),      # [64, 64, 64]\n",
        "\n",
        "            nn.Conv2d(64, 128, 3, 1, 1), # [128, 64, 64]\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2, 0),      # [128, 32, 32]\n",
        "\n",
        "            nn.Conv2d(128, 256, 3, 1, 1), # [256, 32, 32]\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2, 0),      # [256, 16, 16]\n",
        "\n",
        "            nn.Conv2d(256, 512, 3, 1, 1), # [512, 16, 16]\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2, 0),       # [512, 8, 8]\n",
        "            \n",
        "            nn.Conv2d(512, 512, 3, 1, 1), # [512, 8, 8]\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2, 0),       # [512, 4, 4]\n",
        "        )\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(512*4*4, 1024),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(1024, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 11)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.cnn(x)\n",
        "        out = out.view(out.size()[0], -1)\n",
        "        return self.fc(out)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ELtloZnH7WYw"
      },
      "source": [
        "# Training\n",
        "使用training set训练，并使用validation set寻找好的参数"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IZNdvNGg7WYw",
        "outputId": "7ef1cd51-dc93-4c59-edce-c942bda59312"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
            "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[001/030] 48.31 sec(s) Train Acc: 0.238901 Loss: 0.018177 | Val Acc: 0.232362 loss: 0.016908\n",
            "[002/030] 47.81 sec(s) Train Acc: 0.330833 Loss: 0.014988 | Val Acc: 0.322449 loss: 0.015778\n",
            "[003/030] 47.67 sec(s) Train Acc: 0.391141 Loss: 0.013847 | Val Acc: 0.352770 loss: 0.014747\n",
            "[004/030] 47.74 sec(s) Train Acc: 0.425603 Loss: 0.012892 | Val Acc: 0.418950 loss: 0.012953\n",
            "[005/030] 47.77 sec(s) Train Acc: 0.472735 Loss: 0.011952 | Val Acc: 0.437609 loss: 0.012704\n",
            "[006/030] 47.58 sec(s) Train Acc: 0.500912 Loss: 0.011399 | Val Acc: 0.372303 loss: 0.014520\n",
            "[007/030] 47.69 sec(s) Train Acc: 0.527772 Loss: 0.010691 | Val Acc: 0.370554 loss: 0.018394\n",
            "[008/030] 47.70 sec(s) Train Acc: 0.550071 Loss: 0.010082 | Val Acc: 0.462099 loss: 0.012944\n",
            "[009/030] 47.61 sec(s) Train Acc: 0.573485 Loss: 0.009646 | Val Acc: 0.512536 loss: 0.011806\n",
            "[010/030] 47.67 sec(s) Train Acc: 0.600041 Loss: 0.009040 | Val Acc: 0.477843 loss: 0.013142\n",
            "[011/030] 47.59 sec(s) Train Acc: 0.618488 Loss: 0.008685 | Val Acc: 0.504082 loss: 0.012140\n",
            "[012/030] 47.53 sec(s) Train Acc: 0.622137 Loss: 0.008535 | Val Acc: 0.540816 loss: 0.011109\n",
            "[013/030] 47.58 sec(s) Train Acc: 0.663592 Loss: 0.007605 | Val Acc: 0.564431 loss: 0.010789\n",
            "[014/030] 47.57 sec(s) Train Acc: 0.678289 Loss: 0.007272 | Val Acc: 0.511079 loss: 0.012758\n",
            "[015/030] 47.62 sec(s) Train Acc: 0.682749 Loss: 0.007115 | Val Acc: 0.535277 loss: 0.011260\n",
            "[016/030] 47.65 sec(s) Train Acc: 0.707987 Loss: 0.006666 | Val Acc: 0.523032 loss: 0.011700\n",
            "[017/030] 47.49 sec(s) Train Acc: 0.703426 Loss: 0.006728 | Val Acc: 0.549854 loss: 0.011104\n",
            "[018/030] 47.56 sec(s) Train Acc: 0.730995 Loss: 0.006072 | Val Acc: 0.526239 loss: 0.013970\n",
            "[019/030] 47.65 sec(s) Train Acc: 0.736469 Loss: 0.006002 | Val Acc: 0.620408 loss: 0.009482\n",
            "[020/030] 47.69 sec(s) Train Acc: 0.733023 Loss: 0.006046 | Val Acc: 0.543440 loss: 0.012502\n",
            "[021/030] 47.71 sec(s) Train Acc: 0.757957 Loss: 0.005345 | Val Acc: 0.596501 loss: 0.011029\n",
            "[022/030] 47.76 sec(s) Train Acc: 0.775086 Loss: 0.005110 | Val Acc: 0.648397 loss: 0.009039\n",
            "[023/030] 47.70 sec(s) Train Acc: 0.807318 Loss: 0.004399 | Val Acc: 0.592711 loss: 0.011135\n",
            "[024/030] 47.50 sec(s) Train Acc: 0.803061 Loss: 0.004418 | Val Acc: 0.637609 loss: 0.009618\n",
            "[025/030] 47.48 sec(s) Train Acc: 0.814413 Loss: 0.004230 | Val Acc: 0.583090 loss: 0.011741\n",
            "[026/030] 47.54 sec(s) Train Acc: 0.787249 Loss: 0.004871 | Val Acc: 0.659767 loss: 0.009005\n",
            "[027/030] 47.40 sec(s) Train Acc: 0.825664 Loss: 0.003854 | Val Acc: 0.547813 loss: 0.013769\n",
            "[028/030] 47.66 sec(s) Train Acc: 0.831239 Loss: 0.003781 | Val Acc: 0.675219 loss: 0.009435\n",
            "[029/030] 47.69 sec(s) Train Acc: 0.862153 Loss: 0.003108 | Val Acc: 0.682216 loss: 0.009232\n",
            "[030/030] 47.68 sec(s) Train Acc: 0.846949 Loss: 0.003418 | Val Acc: 0.666764 loss: 0.009809\n"
          ]
        }
      ],
      "source": [
        "model = Classifier().cuda()\n",
        "loss = nn.CrossEntropyLoss() # 因為是 classification task，所以 loss 使用 CrossEntropyLoss\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001) # optimizer 使用 Adam\n",
        "num_epoch = 30\n",
        "\n",
        "for epoch in range(num_epoch):\n",
        "    epoch_start_time = time.time()\n",
        "    train_acc = 0.0\n",
        "    train_loss = 0.0\n",
        "    val_acc = 0.0\n",
        "    val_loss = 0.0\n",
        "\n",
        "    model.train() # 確保 model 是在 train model (開啟 Dropout 等...)\n",
        "    for i, data in enumerate(train_loader):\n",
        "        optimizer.zero_grad() # 用 optimizer 將 model 參數的 gradient 歸零\n",
        "        train_pred = model(data[0].cuda()) # 利用 model 得到預測的機率分佈 這邊實際上就是去呼叫 model 的 forward 函數\n",
        "        batch_loss = loss(train_pred, data[1].cuda()) # 計算 loss （注意 prediction 跟 label 必須同時在 CPU 或是 GPU 上）\n",
        "        batch_loss.backward() # 利用 back propagation 算出每個參數的 gradient\n",
        "        optimizer.step() # 以 optimizer 用 gradient 更新參數值\n",
        "\n",
        "        train_acc += np.sum(np.argmax(train_pred.cpu().data.numpy(), axis=1) == data[1].numpy())\n",
        "        train_loss += batch_loss.item()\n",
        "    \n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for i, data in enumerate(val_loader):\n",
        "            val_pred = model(data[0].cuda())\n",
        "            batch_loss = loss(val_pred, data[1].cuda())\n",
        "\n",
        "            val_acc += np.sum(np.argmax(val_pred.cpu().data.numpy(), axis=1) == data[1].numpy())\n",
        "            val_loss += batch_loss.item()\n",
        "\n",
        "        #將結果 print 出來\n",
        "        print('[%03d/%03d] %2.2f sec(s) Train Acc: %3.6f Loss: %3.6f | Val Acc: %3.6f loss: %3.6f' % \\\n",
        "            (epoch + 1, num_epoch, time.time()-epoch_start_time, \\\n",
        "             train_acc/train_set.__len__(), train_loss/train_set.__len__(), val_acc/val_set.__len__(), val_loss/val_set.__len__()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xRnaEdV97WYx"
      },
      "source": [
        "得到好的参数后，使用training set和validation set共同训练，data量变多，模型效果较好"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "2RC4lL6n7WYx"
      },
      "outputs": [],
      "source": [
        "train_val_x = np.concatenate((train_x, val_x), axis=0)\n",
        "train_val_y = np.concatenate((train_y, val_y), axis=0)\n",
        "train_val_set = ImgDataset(train_val_x, train_val_y, train_transform)\n",
        "train_val_loader = DataLoader(train_val_set, batch_size=batch_size, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Y6KqqIx7WYx",
        "outputId": "b7aec12b-8804-4e75-f1db-19c164fe4c44"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[001/030] 56.77 sec(s) Train Acc: 0.257972 Loss: 0.016756\n",
            "[002/030] 56.79 sec(s) Train Acc: 0.385229 Loss: 0.013763\n",
            "[003/030] 57.04 sec(s) Train Acc: 0.449985 Loss: 0.012375\n",
            "[004/030] 57.05 sec(s) Train Acc: 0.503986 Loss: 0.011245\n",
            "[005/030] 56.95 sec(s) Train Acc: 0.552046 Loss: 0.010172\n",
            "[006/030] 57.00 sec(s) Train Acc: 0.582732 Loss: 0.009434\n",
            "[007/030] 56.85 sec(s) Train Acc: 0.621089 Loss: 0.008568\n",
            "[008/030] 56.66 sec(s) Train Acc: 0.643577 Loss: 0.008027\n",
            "[009/030] 56.79 sec(s) Train Acc: 0.665012 Loss: 0.007540\n",
            "[010/030] 56.96 sec(s) Train Acc: 0.683890 Loss: 0.007177\n",
            "[011/030] 56.84 sec(s) Train Acc: 0.701940 Loss: 0.006722\n",
            "[012/030] 56.96 sec(s) Train Acc: 0.714801 Loss: 0.006457\n",
            "[013/030] 57.07 sec(s) Train Acc: 0.734356 Loss: 0.005925\n",
            "[014/030] 56.92 sec(s) Train Acc: 0.748721 Loss: 0.005672\n",
            "[015/030] 56.96 sec(s) Train Acc: 0.771134 Loss: 0.005200\n",
            "[016/030] 56.86 sec(s) Train Acc: 0.779332 Loss: 0.004935\n",
            "[017/030] 56.80 sec(s) Train Acc: 0.787229 Loss: 0.004739\n",
            "[018/030] 56.77 sec(s) Train Acc: 0.801895 Loss: 0.004411\n",
            "[019/030] 56.85 sec(s) Train Acc: 0.808288 Loss: 0.004232\n",
            "[020/030] 56.84 sec(s) Train Acc: 0.831303 Loss: 0.003764\n",
            "[021/030] 56.89 sec(s) Train Acc: 0.837169 Loss: 0.003589\n",
            "[022/030] 56.86 sec(s) Train Acc: 0.844540 Loss: 0.003375\n",
            "[023/030] 56.84 sec(s) Train Acc: 0.862741 Loss: 0.003078\n",
            "[024/030] 56.81 sec(s) Train Acc: 0.871616 Loss: 0.002798\n",
            "[025/030] 56.70 sec(s) Train Acc: 0.880190 Loss: 0.002637\n",
            "[026/030] 56.43 sec(s) Train Acc: 0.887711 Loss: 0.002469\n",
            "[027/030] 56.36 sec(s) Train Acc: 0.899594 Loss: 0.002219\n",
            "[028/030] 56.29 sec(s) Train Acc: 0.902151 Loss: 0.002180\n",
            "[029/030] 56.26 sec(s) Train Acc: 0.914786 Loss: 0.001915\n",
            "[030/030] 56.25 sec(s) Train Acc: 0.915238 Loss: 0.001912\n"
          ]
        }
      ],
      "source": [
        "model_best = Classifier().cuda()\n",
        "loss = nn.CrossEntropyLoss() # 因為是 classification task，所以 loss 使用 CrossEntropyLoss\n",
        "optimizer = torch.optim.Adam(model_best.parameters(), lr=0.001) # optimizer 使用 Adam\n",
        "num_epoch = 30\n",
        "\n",
        "for epoch in range(num_epoch):\n",
        "    epoch_start_time = time.time()\n",
        "    train_acc = 0.0\n",
        "    train_loss = 0.0\n",
        "\n",
        "    model_best.train()\n",
        "    for i, data in enumerate(train_val_loader):\n",
        "        optimizer.zero_grad()\n",
        "        train_pred = model_best(data[0].cuda())\n",
        "        batch_loss = loss(train_pred, data[1].cuda())\n",
        "        batch_loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_acc += np.sum(np.argmax(train_pred.cpu().data.numpy(), axis=1) == data[1].numpy())\n",
        "        train_loss += batch_loss.item()\n",
        "\n",
        "        #將結果 print 出來\n",
        "    print('[%03d/%03d] %2.2f sec(s) Train Acc: %3.6f Loss: %3.6f' % \\\n",
        "      (epoch + 1, num_epoch, time.time()-epoch_start_time, \\\n",
        "      train_acc/train_val_set.__len__(), train_loss/train_val_set.__len__()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A5_qOjWJ7WYx"
      },
      "source": [
        "# Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "q2V8Vi2b7WYy"
      },
      "outputs": [],
      "source": [
        "test_set = ImgDataset(test_x, transform=test_transform)\n",
        "test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "bsXBoIEs7WYy"
      },
      "outputs": [],
      "source": [
        "model_best.eval()\n",
        "prediction = []\n",
        "with torch.no_grad():\n",
        "  for i, data in enumerate(test_loader):\n",
        "    test_pred = model_best(data.cuda())\n",
        "    test_label = np.argmax(test_pred.cpu().data.numpy(), axis=1)\n",
        "    for y in test_label:\n",
        "      prediction.append(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "AQfWjG4_7WYy"
      },
      "outputs": [],
      "source": [
        "# 结果写入csv\n",
        "with open('prediction.csv', 'w') as f:\n",
        "  f.write('Id,Category\\n')\n",
        "  for i, y in enumerate(prediction):\n",
        "    f.write('{},{}\\n'.format(i, y)) "
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "“CNN.ipynb”的副本",
      "provenance": []
    },
    "interpreter": {
      "hash": "dca0ade3e726a953b501b15e8e990130d2b7799f14cfd9f4271676035ebe5511"
    },
    "kernelspec": {
      "display_name": "Python 3.8.11 64-bit ('base': conda)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.11"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
