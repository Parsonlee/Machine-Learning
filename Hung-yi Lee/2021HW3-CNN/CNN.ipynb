{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN\n",
    "\n",
    "kaggle: https://www.kaggle.com/competitions/ml2021spring-hw3/overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, ConcatDataset, Subset\n",
    "from PIL import Image\n",
    "# # 合并数据集用\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import DatasetFolder\n",
    "from torchvision import models\n",
    "\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset, DataLoader, Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tfm = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "    \n",
    "    transforms.AutoAugment(transforms.AutoAugmentPolicy.IMAGENET),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    \n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "test_tfm = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "\n",
    "# 构建数据集\n",
    "train_set = DatasetFolder('food-11/training/labeled', loader=lambda x: Image.open(x), extensions='jpg', transform=train_tfm)\n",
    "val_set = DatasetFolder('food-11/validation', loader=lambda x: Image.open(x), extensions='jpg', transform=test_tfm)\n",
    "test_set = DatasetFolder('food-11/testing', loader=lambda x: Image.open(x), extensions='jpg', transform=test_tfm)\n",
    "\n",
    "# 构建数据加载器\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=8, pin_memory=True)\n",
    "valid_loader = DataLoader(val_set, batch_size=batch_size, shuffle=False, num_workers=8, pin_memory=True)\n",
    "test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(self, Classifier).__init__()\n",
    "\n",
    "        # input image size: [3, 128, 128]\n",
    "        self.model = models.resnet18(pretrained=False)\n",
    "        self.model.fc = nn.Linear(512, 11)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用 semi-supervised learning 提高performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pseudo_label(dataset, model, threshold=0.65):\n",
    "    # This functions generates pseudo-labels of a dataset using given model.\n",
    "    # It returns an instance of DatasetFolder containing images whose prediction confidences exceed a given threshold.\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "    data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "    model.eval()\n",
    "    softmax = nn.Softmax(dim=1)\n",
    "    for batch in tqdm(data_loader):\n",
    "        img, _ = batch\n",
    "        with torch.no_grad():\n",
    "            logit = model(img.to(device))\n",
    "        probs = softmax(logit)  # size: batch_size x 11\n",
    "        \n",
    "        labels = probs.argmax(dim=1)\n",
    "        batch = img, labels\n",
    "        dataset = Subset(dataset, dataset.indices[labels > 0])\n",
    "        ConcatDataset([dataset, batch])\n",
    "\n",
    "    model.train()\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.available else 'cpu'\n",
    "model = Classifier().to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-5)\n",
    "epochs = 30\n",
    "do_semi = False\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    if do_semi:\n",
    "        pseudo_set = get_pseudo_label(train_set, model)\n",
    "        concat_dataset = ConcatDataset([train_set, pseudo_set])\n",
    "        train_loader = DataLoader(concat_dataset, batch_size=batch_size, shuffle=True, num_workers=8, pin_memory=True)\n",
    "\n",
    "    model.train()\n",
    "    train_loss = []\n",
    "    train_acc = []\n",
    "\n",
    "    for batch in tqdm(train_loader):\n",
    "        imgs, labels = batch\n",
    "        logits = model(imgs.to(device))\n",
    "        loss = criterion(logits, labels.to(device))\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        # 梯度剪裁\n",
    "        grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=10)\n",
    "        optimizer.step()\n",
    "        acc = (logits.argmax(dim=-1) == labels).float().mean()\n",
    "        train_loss.append(loss.item())\n",
    "        train_acc.append(acc)\n",
    "\n",
    "    trian_loss = sum(trian_loss) / len(train_loss)\n",
    "    train_acc = sum(train_acc) / len(train_acc)\n",
    "    \n",
    "    print(f\"[ Train | {epoch + 1:03d}/{epochs:03d} ] loss = {train_loss:.5f}, acc = {train_acc:.5f}\")\n",
    "\n",
    "\n",
    "    model.eval()\n",
    "    valid_loss = []\n",
    "    valid_acc = []\n",
    "    for batch in tqdm(valid_loader):\n",
    "        imgs, labels = batch\n",
    "        with torch.no_grad():\n",
    "            logits = model(imgs.to(device))\n",
    "            loss = criterion(logits, labels.to(device))\n",
    "            acc = (logits.argmax(dim=-1) == labels).float().mean()\n",
    "            valid_loss.append(loss.item())\n",
    "            valid_acc.append(acc)\n",
    "\n",
    "    valid_loss = sum(valid_loss) / len(valid_loss)\n",
    "    valid_acc = sum(valid_acc) / len(valid_acc)\n",
    "\n",
    "    print(f\"[ Valid | {epoch + 1:03d}/{epochs:03d} ] loss = {valid_loss:.5f}, acc = {valid_acc:.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "predictions = []\n",
    "\n",
    "for batch in tqdm(test_loader):\n",
    "    # A batch consists of image data and corresponding labels.\n",
    "    # But here the variable \"labels\" is useless since we do not have the ground-truth.\n",
    "    # If printing out the labels, you will find that it is always 0.\n",
    "    # This is because the wrapper (DatasetFolder) returns images and labels for each batch,\n",
    "    # so we have to create fake labels to make it work normally.\n",
    "    imgs, labels = batch\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = model(imgs.to(device))\n",
    "\n",
    "    predictions.extend(logits.argmax(dim=-1).cpu().numpy().tolist())\n",
    "\n",
    "predictions"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0e963d61ae5592af78c1a29f643d857bd502442649449ec5cf61b348680e7239"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 ('dl')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
