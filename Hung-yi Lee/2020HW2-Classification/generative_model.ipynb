{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "import numpy as np\n",
    "\n",
    "x_train_fpath = './data/X_train'\n",
    "y_train_fpath = './data/Y_train'\n",
    "x_test_fpath  = './data/X_test'\n",
    "\n",
    "with open(x_train_fpath, mode = 'r') as f:\n",
    "    next(f)\n",
    "    x_train = np.array([line.strip('\\n').split(',')[1:] for line in f], dtype = float)\n",
    "\n",
    "with open(y_train_fpath, mode = 'r') as f:\n",
    "    next(f)\n",
    "    y_train = np.array([line.strip('\\n').split(',')[1] for line in f], dtype = float)\n",
    "    \n",
    "with open(x_test_fpath, mode = 'r') as f:\n",
    "    next(f)\n",
    "    x_test  = np.array([line.strip('\\n').split(',')[1:] for line in f], dtype = float)\n",
    "    \n",
    "print('x_train :\\n',x_train,x_train.shape,'\\n')\n",
    "print('y_train :\\n',y_train,y_train.shape,'\\n')\n",
    "print('x_test :\\n',x_test,x_test.shape)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "x_train :\n",
      " [[33.  1.  0. ... 52.  0.  1.]\n",
      " [63.  1.  0. ... 52.  0.  1.]\n",
      " [71.  0.  0. ...  0.  0.  1.]\n",
      " ...\n",
      " [16.  0.  0. ...  8.  1.  0.]\n",
      " [48.  1.  0. ... 52.  0.  1.]\n",
      " [48.  0.  0. ...  0.  0.  1.]] (54256, 510) \n",
      "\n",
      "y_train :\n",
      " [1. 0. 0. ... 0. 0. 0.] (54256,) \n",
      "\n",
      "x_test :\n",
      " [[37.  1.  0. ... 52.  0.  1.]\n",
      " [48.  1.  0. ... 52.  0.  1.]\n",
      " [68.  0.  0. ...  0.  1.  0.]\n",
      " ...\n",
      " [38.  1.  0. ... 52.  0.  1.]\n",
      " [17.  0.  0. ... 40.  1.  0.]\n",
      " [22.  0.  0. ... 25.  1.  0.]] (27622, 510)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "def _normalize(x, train = True, specified_column = None, x_mean = None, x_std = None):\n",
    "    '''\n",
    "    This function normalizes specific columns of x\n",
    "    注意，testing data要跟training data的normalize方式一致，要用training data的mean和std，\n",
    "    因此还需要input已知的x_mean和x_std\n",
    "    '''\n",
    "    # 如果没有指定列，那就穷举所有列，这里np.arange类似于range函数，只不过前者创造的对象是array类型\n",
    "    if specified_column == None:\n",
    "        specified_column = np.arange(x.shape[1])\n",
    "    \n",
    "    # train=True: for training data; train=False: for testing data，只计算training data的mean和std\n",
    "    if train:\n",
    "        # axis=0，对指定列求mean，注意np.mean返回的是一个列向量，因此需要用reshape(1,-1)转化成行向量\n",
    "        x_mean = np.mean(x[:, specified_column], axis = 0).reshape(1, -1)\n",
    "        # axis=0，对指定列求std\n",
    "        x_std  = np.std(x[:, specified_column], axis = 0).reshape(1, -1)\n",
    "     \n",
    "    # 对指定列进行normalize，注意相减的两个向量行数不同但列数相同，相当于前者的每一行都减去x_mean这个行向量，除法同理\n",
    "    # 分母加一个很小很小的数是为了避免标准差为0\n",
    "    x[:, specified_column] = (x[:, specified_column] - x_mean) / (x_std + 1e-8)\n",
    "    \n",
    "    return x, x_mean, x_std"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "# normalize training data and testing data\n",
    "x_train, x_mean, x_std = _normalize(x_train, train = True)\n",
    "x_test, _, _ = _normalize(x_test, train = False, x_mean = x_mean, x_std = x_std)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "# zip的作用是把x和y打包成一个元组，然后根据y的值就能够挑选出所有y=0的x和y=1的x\n",
    "x_train_0 = np.array([x for x, y in zip(x_train, y_train) if y == 0])\n",
    "x_train_1 = np.array([x for x, y in zip(x_train, y_train) if y == 1])\n",
    "\n",
    "# 对两组x重新求mean\n",
    "mean_0 = np.mean(x_train_0, axis = 0)\n",
    "mean_1 = np.mean(x_train_1, axis = 0)\n",
    "\n",
    "# 计算feature的维数\n",
    "data_dim = x_train.shape[1]\n",
    "\n",
    "# 计算in-class covariance\n",
    "cov_0 = np.zeros((data_dim, data_dim))\n",
    "cov_1 = np.zeros((data_dim, data_dim))\n",
    "\n",
    "for x in x_train_0:\n",
    "    cov_0 += np.dot(np.transpose([x - mean_0]), [x - mean_0]) / x_train_0.shape[0]\n",
    "for x in x_train_1:\n",
    "    cov_1 += np.dot(np.transpose([x - mean_1]), [x - mean_1]) / x_train_1.shape[0]\n",
    "    \n",
    "# 对in-class covariance进行加权平均，并用来共享\n",
    "cov = (cov_0 * x_train_0.shape[0] + cov_1 * x_train_1.shape[0]) / (x_train_0.shape[0] + x_train_1.shape[0])\n",
    "\n",
    "cov"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[ 0.97796336, -0.16810408,  0.02986219, ..., -0.07983857,\n",
       "        -0.02807772,  0.02807772],\n",
       "       [-0.16810408,  0.99154044, -0.19823935, ...,  0.48773055,\n",
       "        -0.02450272,  0.02450272],\n",
       "       [ 0.02986219, -0.19823935,  0.97001985, ...,  0.07409483,\n",
       "         0.00484927, -0.00484927],\n",
       "       ...,\n",
       "       [-0.07983857,  0.48773055,  0.07409483, ...,  0.89572619,\n",
       "        -0.02888793,  0.02888793],\n",
       "       [-0.02807772, -0.02450272,  0.00484927, ..., -0.02888793,\n",
       "         0.99868338, -0.99868338],\n",
       "       [ 0.02807772,  0.02450272, -0.00484927, ...,  0.02888793,\n",
       "        -0.99868338,  0.99868338]])"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "def _sigmoid(z):\n",
    "    '''\n",
    "    sigmoid function can be used to calculate probability\n",
    "    To avoid overflow, minimum/maximum output value is set\n",
    "    '''\n",
    "    # np.clip(a, a_min, a_max)将数组a限制在a_min和a_max之间，超出范围的值将被赋以边界值\n",
    "    return np.clip(1 / (1.0 + np.exp(-z)), 1e-8, 1 - (1e-8))\n",
    "\n",
    "def _f(x, w, b):\n",
    "    '''\n",
    "    logistic regression function, parameterized by w and b\n",
    "    \n",
    "    Arguements:\n",
    "        X: input data, shape = [batch_size, data_dimension]\n",
    "        w: weight vector, shape = [data_dimension, ]\n",
    "        b: bias, scalar\n",
    "    output:\n",
    "        predicted probability of each row of X being positively labeled, shape = [batch_size, ]\n",
    "    '''\n",
    "    # np.dot特别适合用来计算x*w，无需转置，直接就是N维x的每一行与一维w相乘得到的结果汇总成一个一维的y\n",
    "    return _sigmoid(np.matmul(x, w) + b)\n",
    "\n",
    "def _predict(x, w, b):\n",
    "    '''\n",
    "    This function returns a truth value prediction for each row of x\n",
    "    by round function to make 0 or 1\n",
    "    '''\n",
    "    # 利用round函数的四舍五入功能把概率转化成0或1\n",
    "    return np.round(_f(x, w, b)).astype(int)\n",
    "    \n",
    "def _accuracy(y_predict, y_label):\n",
    "    '''\n",
    "    This function calculates prediction accuracy\n",
    "    '''\n",
    "    # 预测值和标签值相减，取绝对值后再求平均，相当于预测错误的个数(差为1)/总个数，即错误率，1-错误率即正确率\n",
    "    acc = 1 - np.mean(np.abs(y_predict - y_label))\n",
    "    \n",
    "    return acc"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "# Compute inverse of covariance matrix.\n",
    "# Since covariance matrix may be nearly singular, np.linalg.inv() may give a large numerical error.\n",
    "# Via SVD decomposition, one can get matrix inverse efficiently and accurately.\n",
    "u, s, v = np.linalg.svd(cov, full_matrices = False)\n",
    "inv = np.dot(v.T * 1 / s, u.T)\n",
    "\n",
    "# Directly compute weights and bias\n",
    "w = np.dot(inv, mean_0 - mean_1)\n",
    "b =  (-0.5) * np.dot(mean_0, np.dot(inv, mean_0)) + 0.5 * np.dot(mean_1, np.dot(inv, mean_1))\\\n",
    "    + np.log(float(x_train_0.shape[0]) / x_train_1.shape[0]) \n",
    "\n",
    "# Compute accuracy on training set\n",
    "y_train_predict = 1 - _predict(x_train, w, b)\n",
    "print('Training accuracy: {}'.format(_accuracy(y_train_predict, y_train)))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training accuracy: 0.873820406959599\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "import csv\n",
    "y_test_predict = 1 - _predict(x_test, w, b)\n",
    "with open('predict_generative_model.csv', mode = 'w', newline = '') as f:\n",
    "    csv_writer = csv.writer(f)\n",
    "    header = ['id', 'label']\n",
    "    csv_writer.writerow(header)\n",
    "    for i in range(y_test_predict.shape[0]):\n",
    "        row = [str(i), y_test_predict[i]]\n",
    "        csv_writer.writerow(row)"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.11",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.11 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "dca0ade3e726a953b501b15e8e990130d2b7799f14cfd9f4271676035ebe5511"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}